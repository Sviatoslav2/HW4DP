{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4 - Dealing with noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Data Preparation Course at UCU, 2019_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB\n",
    "\n",
    "__1) Which programming languages to use?__\n",
    "\n",
    "We recommend to use Python for this task, but if you find working library alternatives for the algorithms we\n",
    "use in this assignment in R, you are free to work with that as well.\n",
    "\n",
    "__2) What libraries/packages to use?__\n",
    "\n",
    "You are free to choose any appropriate libraries (good choice would be __pandas__, __numpy__,\n",
    "__scicit-learn__).\n",
    "\n",
    "__3) How to summarize my homework?__\n",
    "\n",
    "The best way is to create an Jupyter/R notebook with code and explanations for each strategy. In case you\n",
    "are not familiar with these tools, you can create a Python/R scripts and write explanations as comments.\n",
    "However, we strongly recommend you to use Jupyter/R notebooks, as those are #1 tools in applied data\n",
    "analysis nowadays.\n",
    "\n",
    "__4) Useful links__\n",
    "\n",
    "1. [Deaing with Noisy Data in Data Science.](https://medium.com/analytics-vidhya/dealing-with-noisy-data-in-data-science-e177a4e32621)\n",
    "2. [Decision trees in Scikit-learn.](https://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "In this homework you will investigate the impact of different types of noise on the accuracy of classification\n",
    "model based on __<font color=\"black\">[(Census Income dataset)](https://archive.ics.uci.edu/ml/datasets/Census+Income)</font>__. Noise is an unavoidable problem which affects all stages of Data Mining process, so it is extremely important to learn how to deal with the noise in the most appropriate way. \n",
    "\n",
    "### __1) Logistic regression.__\n",
    "\n",
    "Similar to previous assignment, you’ll have to train multiple logistic regression models. We encourage you to use provided jupyter notebook with working template of logistic regression for Census dataset. Please remember that LR is not the main topic of this assignment, so do not bother yourself tuning your models. The purpose of this assignment is to investigate the negative impact of noise in your dataset on the accuracy of classification and learn basic methods of dealing with problems of this type.\n",
    "\n",
    "Regarding missing values in the dataset - you need to impute them using __global most common substitution strategy__ from the previous assignment.\n",
    "\n",
    "__Treat dataset you obtain after missing values imputation as an original one. All further\n",
    "modification in this homework perform on this dataset, not on the one you have before missing\n",
    "values imputation.__\n",
    "\n",
    "__1.1.__ Train original logistic regression model provided in jupyter notebook. Save values of train and test\n",
    "classification accuracy scores for future comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0.000000\n",
      "workclass         5.638647\n",
      "fnlwgt            0.000000\n",
      "education_num     0.000000\n",
      "marital-status    0.000000\n",
      "occupation        5.660146\n",
      "relationship      0.000000\n",
      "race              0.000000\n",
      "sex               0.000000\n",
      "capital-gain      0.000000\n",
      "capital-loss      0.000000\n",
      "hours-per-week    0.000000\n",
      "native-country    1.790486\n",
      "y                 0.000000\n",
      "dtype: float64\n",
      "age               0.0\n",
      "workclass         0.0\n",
      "fnlwgt            0.0\n",
      "education_num     0.0\n",
      "marital-status    0.0\n",
      "occupation        0.0\n",
      "relationship      0.0\n",
      "race              0.0\n",
      "sex               0.0\n",
      "capital-gain      0.0\n",
      "capital-loss      0.0\n",
      "hours-per-week    0.0\n",
      "native-country    0.0\n",
      "y                 0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education_num  marital-status  occupation  \\\n",
       "0       39          5   77516             13               4           0   \n",
       "1       50          4   83311             13               2           3   \n",
       "2       38          2  215646              9               0           5   \n",
       "3       53          2  234721              7               2           5   \n",
       "4       28          2  338409             13               2           9   \n",
       "...    ...        ...     ...            ...             ...         ...   \n",
       "32556   27          2  257302             12               2          12   \n",
       "32557   40          2  154374              9               2           6   \n",
       "32558   58          2  151910              9               6           0   \n",
       "32559   22          2  201490              9               4           0   \n",
       "32560   52          3  287927              9               2           3   \n",
       "\n",
       "       relationship  race  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                 1     4    1          2174             0              40   \n",
       "1                 0     4    1             0             0              13   \n",
       "2                 1     4    1             0             0              40   \n",
       "3                 0     2    1             0             0              40   \n",
       "4                 5     2    0             0             0              40   \n",
       "...             ...   ...  ...           ...           ...             ...   \n",
       "32556             5     4    0             0             0              38   \n",
       "32557             0     4    1             0             0              40   \n",
       "32558             4     4    0             0             0              40   \n",
       "32559             3     4    1             0             0              20   \n",
       "32560             5     4    0         15024             0              40   \n",
       "\n",
       "       native-country  y  \n",
       "0                  38  0  \n",
       "1                  38  0  \n",
       "2                  38  0  \n",
       "3                  38  0  \n",
       "4                   4  0  \n",
       "...               ... ..  \n",
       "32556              38  0  \n",
       "32557              38  1  \n",
       "32558              38  0  \n",
       "32559              38  0  \n",
       "32560              38  1  \n",
       "\n",
       "[30162 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOU CAN PLACE YOUR SOLUTION IN THE CELLS LIKE THIS ##\n",
    "#######################################################\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.data',names=['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                                      'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                                      'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'y'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_missing_info(data):\n",
    "    data_missing = data.isna()\n",
    "    data_num_missing = data_missing.sum()\n",
    "    print(data_num_missing / len(data) * 100) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "data = data.replace(\" ?\", np.nan).drop(['education'], axis=1)\n",
    "\n",
    "\n",
    "get_missing_info(data)\n",
    "\n",
    "data = data.dropna()\n",
    "lst_of_columns =['workclass','marital-status','occupation','relationship','race','native-country', \"sex\", \"y\"]\n",
    "le = LabelEncoder()\n",
    "encoded_series = data[lst_of_columns].apply(le.fit_transform)\n",
    "for col in lst_of_columns:\n",
    "    data[col] = encoded_series[col]\n",
    "data = data.dropna()\n",
    "get_missing_info(data)\n",
    "#######################################################\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2) [1pt] Misclassification noise.__\n",
    "\n",
    "__2.1.__ Introduce misclassification in your dataset. Randomly flip $n\\%$ of the target variable (‘y’) values. Try $n = (1, 5, 10, 20)$. Perform this process __only in train dataset__. Leave test dataset unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_flip_𝑛(target, data, procent):\n",
    "    lst = list(data[target].values)\n",
    "    number_of_flips = int(len(lst) / 100 * procent)\n",
    "    for i in range(number_of_flips):\n",
    "        if not data[target].iloc[i]:\n",
    "            data[target].iloc[i] = 1.0\n",
    "        else:\n",
    "            data[target].iloc[i] = 0.0\n",
    "    return shuffle(data)\n",
    "\n",
    "def randomly_flip_test(y_test, procent):\n",
    "    number_of_flips = int(len(y_test) / 100 * procent)\n",
    "    for i in range(number_of_flips):\n",
    "        if not y_test.iloc[i]:\n",
    "            y_test.iloc[i] = 1.0\n",
    "        else:\n",
    "            y_test.iloc[i] = 0.0\n",
    "    return shuffle(y_test)        \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('y', 1), data['y'], test_size = .2, random_state=10)\n",
    "\n",
    "y_test1 = randomly_flip_test(y_test, 1)\n",
    "y_test5 = randomly_flip_test(y_test, 5)\n",
    "y_test10 = randomly_flip_test(y_test, 10)\n",
    "y_test20 = randomly_flip_test(y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.2.__ For each $n$ train separate model. Record train and test accuracy for each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################################\n",
      "Accuracy score on test :  0.7044588098789989\n",
      "f1_score on test :  0.3269158172895432\n",
      "Accuracy score on train :  0.7816320610054291\n",
      "f1_score on train :  0.3883923389437029\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.6819161279628708\n",
      "f1_score on test :  0.1512605042016807\n",
      "Accuracy score on train :  0.7816320610054291\n",
      "f1_score on train :  0.3883923389437029\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.6781037626388198\n",
      "f1_score on test :  0.165807560137457\n",
      "Accuracy score on train :  0.7816320610054291\n",
      "f1_score on train :  0.3883923389437029\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.6653406265539532\n",
      "f1_score on test :  0.16466694249069092\n",
      "Accuracy score on train :  0.7816320610054291\n",
      "f1_score on train :  0.3883923389437029\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.6325211337642964\n",
      "f1_score on test :  0.16308040770101928\n",
      "Accuracy score on train :  0.7816320610054291\n",
      "f1_score on train :  0.3883923389437029\n",
      "#####################################################################################\n"
     ]
    }
   ],
   "source": [
    "def model_fit(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict_test = model.predict(X_test) \n",
    "    \n",
    "    y_predict_train = model.predict(X_train) \n",
    "    \n",
    "    print(\"#####################################################################################\")\n",
    "    print(\"Accuracy score on test : \",accuracy_score(y_test, y_predict_test))\n",
    "    print(\"f1_score on test : \",f1_score(y_test, y_predict_test))\n",
    "    print(\"Accuracy score on train : \",accuracy_score(y_train, y_predict_train))\n",
    "    print(\"f1_score on train : \",f1_score(y_train, y_predict_train))\n",
    "    print(\"#####################################################################################\")\n",
    "    return model, accuracy_score(y_test, y_predict_test) \n",
    "model = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "model, test_score = model_fit(model, X_train, X_test, y_train, y_test)\n",
    "model, _ = model_fit(model, X_train, X_test, y_train, y_test1)\n",
    "model, _ = model_fit(model, X_train, X_test, y_train, y_test5)\n",
    "model, _ = model_fit(model, X_train, X_test, y_train, y_test10)\n",
    "model, _ = model_fit(model, X_train, X_test, y_train, y_test20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.3.__ What is the highest safe fraction (approximately) of misclassified examples? (by ‘safe’, we mean fraction\n",
    "of misclassified examples with which difference of accuracies between original and misclassified model does\n",
    "not exceed 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __3) [1pt] Attribute noise.__\n",
    "\n",
    "__3.0.__ For $n = (1,5,10,20)$ create datasets with different levels of attribute noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data1 = randomly_flip_𝑛(\"y\", data, 1)\n",
    "data5 = randomly_flip_𝑛(\"y\", data, 5)\n",
    "data10 = randomly_flip_𝑛(\"y\", data, 10)\n",
    "data20 = randomly_flip_𝑛(\"y\", data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.__ Introduce attribute noise to the __age__ column. Randomly negate $n\\%$ of the values of this attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data1 = randomly_flip_𝑛(\"age\", data1, random.choice([i for i in range(1,101)]))\n",
    "data5 = randomly_flip_𝑛(\"age\", data5, random.choice([i for i in range(1,101)]))\n",
    "data10 = randomly_flip_𝑛(\"age\", data10, random.choice([i for i in range(1,101)]))\n",
    "data20 = randomly_flip_𝑛(\"age\", data20, random.choice([i for i in range(1,101)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.2.__ Introduce attribute noise to the __education_num__ column. Randomly replace $n\\%$ of the values of this attribute with random large numbers in range $[20,100]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = randomly_flip_𝑛(\"education_num\", data1, random.choice([i for i in range(20,101)]))\n",
    "data5 = randomly_flip_𝑛(\"education_num\", data5, random.choice([i for i in range(20,101)]))\n",
    "data10 = randomly_flip_𝑛(\"education_num\", data10, random.choice([i for i in range(20,101)]))\n",
    "data20 = randomly_flip_𝑛(\"education_num\", data20, random.choice([i for i in range(20,101)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.3.__ Introduce attirute noise to the __race__ column. Randomly replace $n\\%$ of the values of this attribute with\n",
    "any other random race from the set of existing races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_noise(data, procent, target='race'):\n",
    "    values = set(data[target].values)\n",
    "    for i in range(int(len(data[target]) / 100 * procent)):  \n",
    "        data[target].iloc[i] = random.choice(list(values.difference(set([data[target].iloc[i]]))))\n",
    "    return shuffle(data) \n",
    "\n",
    "data1 = race_noise(data1, 1)\n",
    "data5 = race_noise(data5, 5)\n",
    "data10 = race_noise(data10, 10)\n",
    "data20 = race_noise(data20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.4.__ For each $n$ train separate model. Record train and test accuracy for each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data1.drop('y', 1), data1['y'], test_size = .2, random_state=10)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(data5.drop('y', 1), data5['y'], test_size = .2, random_state=10)\n",
    "X_train10, X_test10, y_train10, y_test10 = train_test_split(data10.drop('y', 1), data10['y'], test_size = .2, random_state=10)\n",
    "X_train20, X_test20, y_train20, y_test20 = train_test_split(data20.drop('y', 1), data20['y'], test_size = .2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.5.__ Quantify the degradation of the model after introducing each new level of noise to its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################################\n",
      "Accuracy score on test :  0.7808718713741091\n",
      "f1_score on test :  0.4045045045045045\n",
      "Accuracy score on train :  0.779642753533093\n",
      "f1_score on train :  0.39914114589219124\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.7633018398806564\n",
      "f1_score on test :  0.35791366906474825\n",
      "Accuracy score on train :  0.7650959426416345\n",
      "f1_score on train :  0.36556973360197\n",
      "#####################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Fedoriv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################################\n",
      "Accuracy score on test :  0.7616442897397646\n",
      "f1_score on test :  0.3580357142857143\n",
      "Accuracy score on train :  0.7531186539019438\n",
      "f1_score on train :  0.3545346191353343\n",
      "#####################################################################################\n",
      "#####################################################################################\n",
      "Accuracy score on test :  0.7831924415713575\n",
      "f1_score on test :  0.4129263913824058\n",
      "Accuracy score on train :  0.7753325873430312\n",
      "f1_score on train :  0.36618730270080674\n",
      "#####################################################################################\n"
     ]
    }
   ],
   "source": [
    "model, test_score1 = model_fit(model, X_train1, X_test1, y_train1, y_test1)\n",
    "model, test_score5 = model_fit(model, X_train5, X_test5, y_train5, y_test5)\n",
    "model, test_score10 = model_fit(model, X_train10, X_test10, y_train10, y_test10)\n",
    "model, test_score20 = model_fit(model, X_train20, X_test20, y_train20, y_test20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __4) [1pt] Impact comparison.__\n",
    "\n",
    "__4.1.__ Build a table to compare accuracy of the model on the original dataset with models based on datasets\n",
    "with different types and levels of noise introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class noise comprison:\n",
      "Calss noise n=1% train degradation: -0.07641306149511018\n",
      "Calss noise n=5% train degradation: -0.05884303000165747\n",
      "Calss noise n=10% train degradation: -0.05718547986076572\n",
      "Calss noise n=20% train degradation: -0.07873363169235859\n"
     ]
    }
   ],
   "source": [
    "print(\"Class noise comprison:\")\n",
    "print(\"Calss noise n=1% train degradation:\",test_score - test_score1)\n",
    "print(\"Calss noise n=5% train degradation:\",test_score - test_score5)\n",
    "print(\"Calss noise n=10% train degradation:\",test_score - test_score10)\n",
    "print(\"Calss noise n=20% train degradation:\",test_score - test_score20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4.2.__ What has greater impact on the accuracy of the model: class or attribute noise? How would you explain\n",
    "it? (4-5 sentences)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In our dataset it looks like class noise is afacting score more then attribute noise. It is preatty logical as we have lots of attributes, and when we bring some noise to some of them, the model still can predict the right output class. Alsou the class noise affects all attributes, so it has more effact on the model score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4.3.__ What kind of noise would you address first? Why? (2-3 sentences)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __5) [2pt] Misclassification noise elimination.__\n",
    "\n",
    "__5.1.__ Use training dataset with 10% of misclassified instances which you obtained in __Task 2__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "#data10\n",
    "\n",
    "\n",
    "def get_parts(data, parts_number):\n",
    "    part_div = len(data) // parts_number\n",
    "    return [data.iloc[part_div*i:part_div*(i+1)] for i in range(parts_number)]\n",
    "\n",
    "def fit_for_cros_clasification(lst_models, lst_data):\n",
    "    if len(lst_models) == len(lst_data):\n",
    "        for i,model in enumerate(lst_models):\n",
    "            model.fit(pd.concat([lst_data[index].drop('y',axis=1) for index in range(len(lst_data)) if index != i], axis=0),\n",
    "                      pd.concat([lst_data[index]['y']  for index in range(len(lst_data)) if index != i],axis= 0))\n",
    "        return lst_models\n",
    "    else:\n",
    "        raise ValueError(\"nubers of models and datasets shuld be == \")\n",
    "        \n",
    "\n",
    "data_five1, data_five2, data_five3, data_five4, data_five5  = get_parts(data10, 5)\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "clf4 = tree.DecisionTreeClassifier()\n",
    "clf5 = tree.DecisionTreeClassifier()\n",
    "clf1, clf2, clf3, clf4, clf5 =  fit_for_cros_clasification([clf1, clf2, clf3, clf4, clf5], \n",
    "                                                           [data_five1, data_five2, data_five3, data_five4, data_five5])\n",
    "\n",
    "\n",
    "\n",
    "def outputGenerator(data,yTrue,  clf1, clf2, clf3, clf4):\n",
    "    x1 = clf1.predict(data)\n",
    "    x2 = clf2.predict(data)\n",
    "    x3 = clf3.predict(data)\n",
    "    x4 = clf4.predict(data)\n",
    "    trueYList = yTrue.tolist()\n",
    "    outputList = []\n",
    "    for i in range(len(x1)):\n",
    "        numOfAccurence0 = 0\n",
    "        numOfAccurence1 = 0\n",
    "        if x1[i] == x2[i] and x1[i] == 1:\n",
    "                numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if x1[i] == x3[i] and x1[i] == 1:\n",
    "            numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if x1[i] == x4[i] and x1[i] == 1:\n",
    "            numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if x2[i] == x3[i] and x2[i] == 1:\n",
    "            numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if x2[i] == x4[i] and x2[i] == 1:\n",
    "            numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if x3[i] == x4[i] and x3[i] == 1:\n",
    "            numOfAccurence1 += 1\n",
    "        else:\n",
    "            numOfAccurence0 += 1\n",
    "        if numOfAccurence1 > 4:\n",
    "            outputList.append(1)\n",
    "        else:\n",
    "            outputList.append(0) \n",
    "    return outputList\n",
    "\n",
    "x1 = outputGenerator(data_five1.drop('y',axis=1), data_five1['y'],clf5, clf2, clf3, clf4)\n",
    "x2 = outputGenerator(data_five2.drop('y',axis=1), data_five2['y'],clf5, clf2, clf3, clf4)\n",
    "x3 = outputGenerator(data_five3.drop('y',axis=1), data_five3['y'],clf5, clf2, clf3, clf4)\n",
    "x4 = outputGenerator(data_five4.drop('y',axis=1), data_five4['y'],clf5, clf2, clf3, clf4)\n",
    "x5 = outputGenerator(data_five5.drop('y',axis=1), data_five5['y'],clf5, clf2, clf3, clf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.2.__ Apply Cross-Validated Committees Filter algorithm to identify and fix mislabled instances in this dataset.\n",
    "\n",
    "• You can read the full description of this algorithm in “Data Preprocessing In Data Mining” by S. Garcia,\n",
    "J. Luengo and F. Herrera [page 117, Section 5.3.2].\n",
    "\n",
    "• Use scikit-learn utilities to create and train Decision Tree classifiers for this algorithm. You can read\n",
    "more about them in [__(Decision Trees)__](https://scikit-learn.org/stable/modules/tree.html).\n",
    "\n",
    "• Use $\\Gamma = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass  fnlwgt  education_num  marital-status  occupation  \\\n",
      "19723   0.0          2  180262            0.0               4           3   \n",
      "11369   0.0          2  314177            0.0               4           5   \n",
      "32074   0.0          2  318749            0.0               2          12   \n",
      "31948   0.0          2  130513            0.0               4          11   \n",
      "2250   39.0          2   34028            0.0               0           3   \n",
      "...     ...        ...     ...            ...             ...         ...   \n",
      "11886   0.0          0  161463            0.0               2           7   \n",
      "7734    0.0          2   70261            0.0               4           7   \n",
      "29616  33.0          5  173806            0.0               4           9   \n",
      "14413   0.0          2  238342            0.0               2          13   \n",
      "2085    0.0          2   49115            0.0               2           3   \n",
      "\n",
      "       relationship  race  sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "19723             1     4    0             0             0              40   \n",
      "11369             2     2    1             0             0              40   \n",
      "32074             5     4    0             0             0              35   \n",
      "31948             3     4    0             0             0              40   \n",
      "2250              4     4    0             0             0              48   \n",
      "...             ...   ...  ...           ...           ...             ...   \n",
      "11886             0     2    1             0             0              40   \n",
      "7734              3     4    1             0             0              30   \n",
      "29616             1     4    1             0             0              30   \n",
      "14413             0     4    1             0             0              40   \n",
      "2085              0     4    1             0             0              60   \n",
      "\n",
      "       native-country    y  \n",
      "19723              38  0.0  \n",
      "11369              38  0.0  \n",
      "32074              10  0.0  \n",
      "31948              28  0.0  \n",
      "2250               38  1.0  \n",
      "...               ...  ...  \n",
      "11886              38  0.0  \n",
      "7734               38  0.0  \n",
      "29616              38  0.0  \n",
      "14413              38  0.0  \n",
      "2085               38  0.0  \n",
      "\n",
      "[6032 rows x 14 columns]\n",
      "0\n",
      "Mislabled dat % 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19723</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>314177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>318749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>176711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>274222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>210095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29744</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>162945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20051</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>368561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30160 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass  fnlwgt  education_num  marital-status  occupation  \\\n",
       "19723   0.0          2  180262            0.0               4           3   \n",
       "11369   0.0          2  314177            0.0               4           5   \n",
       "32074   0.0          2  318749            0.0               2          12   \n",
       "31948   0.0          2  130513            0.0               4          11   \n",
       "2250   39.0          2   34028            0.0               0           3   \n",
       "...     ...        ...     ...            ...             ...         ...   \n",
       "10803   0.0          2  176711            0.0               4           0   \n",
       "3657    0.0          2  274222            0.0               2           7   \n",
       "14515   0.0          2  210095            0.0               3           5   \n",
       "29744   0.0          5  162945            0.0               2           3   \n",
       "24536   0.0          2  368561            0.0               2          11   \n",
       "\n",
       "       relationship  race  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "19723             1     4    0             0             0              40   \n",
       "11369             2     2    1             0             0              40   \n",
       "32074             5     4    0             0             0              35   \n",
       "31948             3     4    0             0             0              40   \n",
       "2250              4     4    0             0             0              48   \n",
       "...             ...   ...  ...           ...           ...             ...   \n",
       "10803             3     4    1             0             0              40   \n",
       "3657              0     4    1          7688             0              38   \n",
       "14515             1     4    0             0             0              40   \n",
       "29744             0     2    1         20051             0              55   \n",
       "24536             0     4    1             0             0              55   \n",
       "\n",
       "       native-country    y  \n",
       "19723              38  0.0  \n",
       "11369              38  0.0  \n",
       "32074              10  0.0  \n",
       "31948              28  0.0  \n",
       "2250               38  1.0  \n",
       "...               ...  ...  \n",
       "10803              38  0.0  \n",
       "3657               38  1.0  \n",
       "14515              25  0.0  \n",
       "29744              38  1.0  \n",
       "24536              38  1.0  \n",
       "\n",
       "[30160 rows x 14 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mislabels(x,lstDfy):\n",
    "    mislabels = 0\n",
    "    for i in range(len(x)):\n",
    "        if(x[i] != lstDfy[i]):\n",
    "            mislabels += 1\n",
    "    return mislabels\n",
    "print(data_five1)\n",
    "x1Misslables = mislabels(x1, data_five1['y'].tolist())\n",
    "x2Misslables = mislabels(x2, data_five2['y'].tolist())\n",
    "x3Misslables = mislabels(x3, data_five3['y'].tolist())\n",
    "x4Misslables = mislabels(x4, data_five4['y'].tolist())\n",
    "x5Misslables = mislabels(x5, data_five5['y'].tolist())\n",
    "\n",
    "\n",
    "def mislabels(x,lstDfy):\n",
    "    mislabels = 0\n",
    "    for i in range(len(x)):\n",
    "        if(x[i] != lstDfy[i]):\n",
    "            mislabels += 1\n",
    "    return mislabels\n",
    "\n",
    "totalMislables = x1Misslables + x2Misslables + x3Misslables + x4Misslables + x5Misslables\n",
    "print(totalMislables)\n",
    "\n",
    "percentOfMislabels = (totalMislables * 100)/len(data10)\n",
    "print(\"Mislabled dat %\",percentOfMislabels)\n",
    "\n",
    "\n",
    "def newDf(x, df):\n",
    "    indexes = df.index.tolist()\n",
    "    for i in range(len(x)):\n",
    "        if(df.at[indexes[i],'y'] != x[i]):\n",
    "            df.at[indexes[i],'y'] = x[i]\n",
    "    return df\n",
    "\n",
    "newDf1 = newDf(x1,data_five1)\n",
    "newDf2 = newDf(x2,data_five2)\n",
    "newDf3 = newDf(x3,data_five3)\n",
    "newDf4 = newDf(x4,data_five4)\n",
    "newDf5 = newDf(x5,data_five5)\n",
    "\n",
    "new_data = pd.concat([newDf1,newDf2,newDf3,newDf4,newDf5],axis=0)\n",
    "\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.3.__ What percent of mislabled records you fixed using this method? Is it possible to do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.4.__ Compare the accuracy of the classifier after elimination of mislabeled instances with its accuracy before\n",
    "this procedure was performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
